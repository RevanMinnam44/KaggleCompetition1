{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "1148bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "random.seed(265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "67e74b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/Users/revan/Downloads/congressional_tweet_training_data.csv\")\n",
    "df_test = pd.read_csv(\"/Users/revan/Downloads/congressional_tweet_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "cb17856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['full_text'] = df_train['full_text'].str[1:]\n",
    "df_test['full_text'] = df_test['full_text'].str[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ca5c1bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "translator = str.maketrans('', '', punctuations_list)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "st = nltk.PorterStemmer()\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "12917e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_str):\n",
    "    text_str = text_str.lower()\n",
    "    text_str = re.sub(r\"http\\S+\", \"\", text_str) #removes links\n",
    "    text_str = re.sub(r'\\d+',\"\", text_str)\n",
    "    text_str = re.sub(r'[^\\w\\s]', \" \", text_str) #removes punctuation\n",
    "    text_str = nltk.word_tokenize(text_str)\n",
    "    text_str = [word for word in text_str if word not in STOP_WORDS]\n",
    "    text_str = [word for word in text_str if len(word) > 2 and not re.match(r'\\d+',  word)]\n",
    "    return ' '.join(text_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "e9acdec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"] = df_train[\"full_text\"].map(clean_text)\n",
    "df_test[\"clean_text\"] = df_test[\"full_text\"].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "c3134bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_Stopwords(text):\n",
    "    stopW=stopwords.words('english') #get the english stopwords\n",
    "    return \" \".join([i for i in text.split() if i not in stopW])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "a32d19bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_text']=df_train['clean_text'].apply(lambda x:remove_Stopwords(x))\n",
    "df_test['clean_text']=df_test['clean_text'].apply(lambda x:remove_Stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "be65a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize(text):\n",
    "    # 1. Init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # 2. Lemmatize text with the appropriate POS tag\n",
    "    return \" \".join([lemmatizer.lemmatize(i, get_wordnet_pos(i)) for i in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "cad8ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_text'] = df_train['clean_text'].apply(lambda x:lemmatize(x))\n",
    "df_test['clean_text'] = df_test['clean_text'].apply(lambda x:lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "fce236d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I'm urging the @CDCgov to immediately launch a 24/7 phone hotline to address questions from Americans regarding the #Coronavirus.\\n\\nI'm also urging the agency to hold regular calls with state &amp; local health officials to provide up-to-date info &amp; provide any resources needed. https://t.co/xRzNim8RHM\"\n",
      "today urge cdcgov immediately launch phone hotline address question american regard coronavirus also urge agency hold regular call state amp local health official provide date info amp provide resource need\n"
     ]
    }
   ],
   "source": [
    "df_train[[\"clean_text\",\"full_text\"]].head(1)\n",
    "print(df_train['full_text'].iloc[1])\n",
    "print(df_train['clean_text'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "30133114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[\"clean_hashtags\"] = df_train[\"hashtags\"].map(clean_hashtags)\n",
    "#df_test[\"clean_hashtags\"] = df_test[\"hashtags\"].map(clean_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "272f1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[\"text_2\"] =  df_train[\"clean_hashtags\"] + \" \"  + df_train[\"clean_text\"]  \n",
    "#df_test[\"text_2\"] =   df_test[\"clean_hashtags\"] + \" \" + df_test[\"clean_text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "3f41a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearscv(df):    \n",
    "    #print(df[\"clean_text\"])\n",
    "    print(\"starting linearscv\")\n",
    "    x = df['clean_text'].tolist()\n",
    "    tfid = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,2), max_features=9000, lowercase= True)\n",
    "    tf = tfid.fit_transform(x)\n",
    "    #print('No. of feature_words: ', tfid.get_feature_names())\n",
    "    return (tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "94b15a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df_train, df_test):\n",
    "    y_train = df_train['party_id'].map({'D': 0, 'R': 1}).tolist()\n",
    "    y_test = df_test['party'].map({'D': 0, 'R': 1}).tolist()\n",
    "    x_train = linearscv(df_train)\n",
    "    x_test = linearscv(df_test)\n",
    "    #print(x_train.shape, x_test.shape)\n",
    "    print(\"starting logistic regression\")\n",
    "    clf1 = LogisticRegression(C=2, random_state = 265, max_iter=10000, n_jobs = -1).fit(x_train, y_train)\n",
    "    print(\"starting linear regression\")\n",
    "    clf2 = LinearSVC().fit(x_train, y_train)\n",
    "    #print(\"starting logisticCV regression\")\n",
    "    #clf3 = LogisticRegressionCV(cv = 5, random_state = 265, max_iter=10000, n_jobs = -1).fit(x_train, y_train)\n",
    "    score1 = clf1.score(x_test, y_test)\n",
    "    score2 = clf2.score(x_test, y_test)\n",
    "    #score3 = clf3.score(x_test, y_test)\n",
    "    y_predict = clf2.predict(x_test) \n",
    "    #print(y_predict)\n",
    "    results = [] \n",
    "    results.append([\"LR\" , score1])\n",
    "    results.append([\"SVC\" , score2])\n",
    "    #results.append([\"LRCV\" , score3])\n",
    "    print(pd.DataFrame(results, columns=['label', 'accuracy']))\n",
    "    return  y_predict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "fa8092fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting linearscv\n",
      "starting linearscv\n",
      "starting logistic regression\n",
      "starting linear regression\n",
      "  label  accuracy\n",
      "0    LR  0.607977\n",
      "1   SVC  0.612204\n"
     ]
    }
   ],
   "source": [
    "y_predict = accuracy(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "cb40e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(df_test, y_pred):\n",
    "    df_out = df_test[[\"Id\"]].copy()\n",
    "    df_out[\"party\"] = y_pred\n",
    "    df_out[\"party\"] = df_out[\"party\"].map({0:'D' , 1:'R'})\n",
    "    df_out.to_csv(\"/Users/revan/Downloads/final_submission14.csv\", index=False)\n",
    "    print(df_out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "7b446125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id party\n",
      "0   0     R\n",
      "1   1     D\n",
      "2   2     R\n",
      "3   3     R\n",
      "4   4     R\n",
      "5   5     R\n",
      "6   6     D\n",
      "7   7     R\n",
      "8   8     D\n",
      "9   9     D\n"
     ]
    }
   ],
   "source": [
    "create_output(df_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "08ab6347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_hashtags</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592703</th>\n",
       "      <td>FloridiansHelpingFloridiansFloridaStrong</td>\n",
       "      <td>FloridiansHelpingFloridians FloridaStrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592704</th>\n",
       "      <td>SeeMyOhio11ClevelandAkronOH11</td>\n",
       "      <td>SeeMyOhio11 Cleveland Akron OH11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592705</th>\n",
       "      <td>HeroesActFamiliesFirst</td>\n",
       "      <td>HeroesAct FamiliesFirst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592706</th>\n",
       "      <td>2020Election</td>\n",
       "      <td>2020Election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592707</th>\n",
       "      <td>SmallBiz</td>\n",
       "      <td>SmallBiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592798</th>\n",
       "      <td>publicservicepublicsafety</td>\n",
       "      <td>publicservice publicsafety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592799</th>\n",
       "      <td>StormyDanielsMichaelWolfeJamesComey</td>\n",
       "      <td>StormyDaniels MichaelWolfe JamesComey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592800</th>\n",
       "      <td>CultureOfCorruption</td>\n",
       "      <td>CultureOfCorruption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592801</th>\n",
       "      <td>appcopoliticsCAC16HouseOfCodeco06</td>\n",
       "      <td>app copolitics CAC16 HouseOfCode co06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592802</th>\n",
       "      <td>MuslimBan</td>\n",
       "      <td>MuslimBan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  clean_hashtags  \\\n",
       "592703  FloridiansHelpingFloridiansFloridaStrong   \n",
       "592704             SeeMyOhio11ClevelandAkronOH11   \n",
       "592705                    HeroesActFamiliesFirst   \n",
       "592706                              2020Election   \n",
       "592707                                  SmallBiz   \n",
       "...                                          ...   \n",
       "592798                 publicservicepublicsafety   \n",
       "592799       StormyDanielsMichaelWolfeJamesComey   \n",
       "592800                       CultureOfCorruption   \n",
       "592801         appcopoliticsCAC16HouseOfCodeco06   \n",
       "592802                                 MuslimBan   \n",
       "\n",
       "                                         hashtags  \n",
       "592703  FloridiansHelpingFloridians FloridaStrong  \n",
       "592704           SeeMyOhio11 Cleveland Akron OH11  \n",
       "592705                    HeroesAct FamiliesFirst  \n",
       "592706                               2020Election  \n",
       "592707                                   SmallBiz  \n",
       "...                                           ...  \n",
       "592798                 publicservice publicsafety  \n",
       "592799      StormyDaniels MichaelWolfe JamesComey  \n",
       "592800                        CultureOfCorruption  \n",
       "592801      app copolitics CAC16 HouseOfCode co06  \n",
       "592802                                  MuslimBan  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"text_2\"]].tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ff5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_str):\n",
    "    text_str = text_str.lower()\n",
    "    text_str = re.sub(r\"http\\S+\", \"\", text_str) #removes links\n",
    "    text_str = re.sub(r'\\d+',\"\", text_str)\n",
    "    text_str = re.sub(r'[^\\w\\s]', \" \", text_str) #removes punctuation\n",
    "    tokens = nltk.word_tokenize(text_str)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    lemmatized_sentence = []\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_tagger(x[1])), tagged))\n",
    "    for word, tag in tagged:\n",
    "        if tag is None:\n",
    "            # if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:       \n",
    "            # else use the tag to lemmatize the token\n",
    "            #print(word)\n",
    "            lemmatized_sentence.append(lmtzr.lemmatize(word, pos_tagger(tag)))\n",
    "    lemmatized_sentence = \" \".join(lemmatized_sentence)\n",
    "    word_tokens = nltk.word_tokenize(lemmatized_sentence)\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if len(w) <= 2 or re.match(r'\\d+',  w): continue\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return wordnet.NOUN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
